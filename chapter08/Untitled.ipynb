{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f91648a8-a949-427b-b585-96261c44e89d",
   "metadata": {},
   "source": [
    "#70. 単語ベクトルの和による特徴量\n",
    "\n",
    "\n",
    "問題50で構築した学習データ，検証データ，評価データを行列・ベクトルに変換したい．例えば，学習データについて，すべての事例xi\n",
    "の特徴ベクトルxi\n",
    "を並べた行列X\n",
    "と，正解ラベルを並べた行列（ベクトル）Y\n",
    "を作成したい．\n",
    "\n",
    "X=⎛⎝⎜⎜⎜⎜x1x2…xn⎞⎠⎟⎟⎟⎟∈ℝn×d,Y=⎛⎝⎜⎜⎜⎜y1y2…yn⎞⎠⎟⎟⎟⎟∈ℕn\n",
    "ここで，n\n",
    "は学習データの事例数であり，xi∈ℝd\n",
    "とyi∈ℕ\n",
    "はそれぞれ，i∈{1,…,n}\n",
    "番目の事例の特徴量ベクトルと正解ラベルを表す． なお，今回は「ビジネス」「科学技術」「エンターテイメント」「健康」の4カテゴリ分類である．ℕ<4\n",
    "で4\n",
    "未満の自然数（0\n",
    "を含む）を表すことにすれば，任意の事例の正解ラベルyi\n",
    "はyi∈ℕ<4\n",
    "で表現できる． 以降では，ラベルの種類数をL\n",
    "で表す（今回の分類タスクではL=4\n",
    "である）．\n",
    "\n",
    "i\n",
    "番目の事例の特徴ベクトルxi\n",
    "は，次式で求める．\n",
    "\n",
    "xi=1Ti∑t=1Tiemb(wi,t)\n",
    "ここで，i\n",
    "番目の事例はTi\n",
    "個の（記事見出しの）単語列(wi,1,wi,2,…,wi,Ti)\n",
    "から構成され，emb(w)∈ℝd\n",
    "は単語w\n",
    "に対応する単語ベクトル（次元数はd\n",
    "）である．すなわち，i\n",
    "番目の事例の記事見出しを，その見出しに含まれる単語のベクトルの平均で表現したものがxi\n",
    "である．今回は単語ベクトルとして，問題60でダウンロードしたものを用いればよい．300\n",
    "次元の単語ベクトルを用いたので，d=300\n",
    "である．\n",
    "\n",
    "i\n",
    "番目の事例のラベルyi\n",
    "は，次のように定義する．\n",
    "\n",
    "yi=⎧⎩⎨⎪⎪0123(記事xiが「ビジネス」カテゴリの場合)(記事xiが「科学技術」カテゴリの場合)(記事xiが「エンターテイメント」カテゴリの場合)(記事xiが「健康」カテゴリの場合)\n",
    "なお，カテゴリ名とラベルの番号が一対一で対応付いていれば，上式の通りの対応付けでなくてもよい．\n",
    "\n",
    "以上の仕様に基づき，以下の行列・ベクトルを作成し，ファイルに保存せよ．\n",
    "\n",
    "学習データの特徴量行列: Xtrain∈ℝNt×d\n",
    "学習データのラベルベクトル: Ytrain∈ℕNt\n",
    "検証データの特徴量行列: Xvalid∈ℝNv×d\n",
    "検証データのラベルベクトル: Yvalid∈ℕNv\n",
    "評価データの特徴量行列: Xtest∈ℝNe×d\n",
    "評価データのラベルベクトル: Ytest∈ℕNe\n",
    "なお，Nt,Nv,Ne\n",
    "はそれぞれ，学習データの事例数，検証データの事例数，評価データの事例数である．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "834f29b0-f2fb-42f5-b899-8d1d5eeb7832",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torch\n",
      "  Downloading torch-2.1.0-cp38-none-macosx_10_9_x86_64.whl (146.7 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m146.7/146.7 MB\u001b[0m \u001b[31m10.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting torchvision\n",
      "  Downloading torchvision-0.16.0-cp38-cp38-macosx_10_13_x86_64.whl (1.7 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: filelock in /Users/miuranaoki/.pyenv/versions/3.8.11/envs/100knock/lib/python3.8/site-packages (from torch) (3.12.0)\n",
      "Requirement already satisfied: typing-extensions in /Users/miuranaoki/.pyenv/versions/3.8.11/envs/100knock/lib/python3.8/site-packages (from torch) (4.4.0)\n",
      "Collecting sympy (from torch)\n",
      "  Downloading sympy-1.12-py3-none-any.whl (5.7 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.7/5.7 MB\u001b[0m \u001b[31m23.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting networkx (from torch)\n",
      "  Downloading networkx-3.1-py3-none-any.whl (2.1 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m23.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m31m26.1 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: jinja2 in /Users/miuranaoki/.pyenv/versions/3.8.11/envs/100knock/lib/python3.8/site-packages (from torch) (3.1.2)\n",
      "Requirement already satisfied: fsspec in /Users/miuranaoki/.pyenv/versions/3.8.11/envs/100knock/lib/python3.8/site-packages (from torch) (2023.5.0)\n",
      "Requirement already satisfied: numpy in /Users/miuranaoki/.pyenv/versions/3.8.11/envs/100knock/lib/python3.8/site-packages (from torchvision) (1.23.4)\n",
      "Requirement already satisfied: requests in /Users/miuranaoki/.pyenv/versions/3.8.11/envs/100knock/lib/python3.8/site-packages (from torchvision) (2.28.1)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /Users/miuranaoki/.pyenv/versions/3.8.11/envs/100knock/lib/python3.8/site-packages (from torchvision) (8.4.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/miuranaoki/.pyenv/versions/3.8.11/envs/100knock/lib/python3.8/site-packages (from jinja2->torch) (2.1.1)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /Users/miuranaoki/.pyenv/versions/3.8.11/envs/100knock/lib/python3.8/site-packages (from requests->torchvision) (2.1.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/miuranaoki/.pyenv/versions/3.8.11/envs/100knock/lib/python3.8/site-packages (from requests->torchvision) (3.3)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/miuranaoki/.pyenv/versions/3.8.11/envs/100knock/lib/python3.8/site-packages (from requests->torchvision) (1.26.12)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/miuranaoki/.pyenv/versions/3.8.11/envs/100knock/lib/python3.8/site-packages (from requests->torchvision) (2022.6.15)\n",
      "Collecting mpmath>=0.19 (from sympy->torch)\n",
      "  Downloading mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m536.2/536.2 kB\u001b[0m \u001b[31m24.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: mpmath, sympy, networkx, torch, torchvision\n",
      "Successfully installed mpmath-1.3.0 networkx-3.1 sympy-1.12 torch-2.1.0 torchvision-0.16.0\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.1.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install torch torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c2ee3226-ac2b-4210-b2c3-e7c07ab70ef4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting nltk\n",
      "  Downloading nltk-3.8.1-py3-none-any.whl (1.5 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m17.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: click in /Users/miuranaoki/.pyenv/versions/3.8.11/envs/100knock/lib/python3.8/site-packages (from nltk) (7.1.2)\n",
      "Requirement already satisfied: joblib in /Users/miuranaoki/.pyenv/versions/3.8.11/envs/100knock/lib/python3.8/site-packages (from nltk) (1.2.0)\n",
      "Collecting regex>=2021.8.3 (from nltk)\n",
      "  Downloading regex-2023.10.3-cp38-cp38-macosx_10_9_x86_64.whl (296 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m296.3/296.3 kB\u001b[0m \u001b[31m15.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: tqdm in /Users/miuranaoki/.pyenv/versions/3.8.11/envs/100knock/lib/python3.8/site-packages (from nltk) (4.64.1)\n",
      "Installing collected packages: regex, nltk\n",
      "Successfully installed nltk-3.8.1 regex-2023.10.3\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.1.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2e5f6791-0e74-4480-a4cf-d4a874c71924",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.9196, 0.1557, 0.6710],\n",
      "        [0.5308, 0.8818, 0.7138],\n",
      "        [0.5524, 0.1902, 0.5337],\n",
      "        [0.7483, 0.3296, 0.7331],\n",
      "        [0.4702, 0.7657, 0.2088]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "x = torch.rand(5, 3)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "07c859e8-0e40-4b21-bbcd-ba5f97fe9a8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/miuranaoki/nlp100/100knock-2023/trainee_n-miura/chapter08'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "265284b9-a8d7-422f-9327-98bce29151b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "chapter06.copy/work/train.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "6b853e1f-4a49-4f43-83cb-092d11c004d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  単語をベクトル表現に変換するためのモデルの作成\n",
    "import gensim\n",
    "word2vec_model = gensim.models.KeyedVectors.load_word2vec_format(\"/Users/miuranaoki/nlp100/100knock-2023/trainee_n-miura/chapter07/data/GoogleNews-vectors-negative300.bin\", binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4ebceb39-5fca-4b7c-a6f9-f56e006d9c6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_path = '/Users/miuranaoki/nlp100/100knock-2023/trainee_n-miura/chapter06.copy/work/train.txt'\n",
    "test_data_path = '/Users/miuranaoki/nlp100/100knock-2023/trainee_n-miura/chapter06.copy/work/test.txt'\n",
    "valid_data_path = '/Users/miuranaoki/nlp100/100knock-2023/trainee_n-miura/chapter06.copy/work/valid.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "ff0f5630-21c7-438f-bb6c-85880793b6ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "usage: ipykernel_launcher.py [-h] -p <str>\n",
      "ipykernel_launcher.py: error: the following arguments are required: -p/--path\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "2",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m 2\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import numpy as np\n",
    "import torch\n",
    "import gensim\n",
    "\n",
    "\n",
    "def parse_args():\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument(\"-p\", \"--path\", dest=\"data_path\", type=str,\n",
    "                        metavar='<str>', required=True, help=\"The path to the data\")\n",
    "    args = parser.parse_args()\n",
    "    return args\n",
    "\n",
    "\n",
    "#  入力されたファイルからカテゴリとタイトルを分けて出力\n",
    "#  今後のためにジェネレーターにしておく\n",
    "def make_title_and_category(file_path):\n",
    "    with open(file_path) as fi:\n",
    "        for line in fi:\n",
    "            yield line.rstrip().split('\\t')\n",
    "\n",
    "def clean_text(text):\n",
    "    text = re.sub(r'[\\\"\\'.,:;\\(\\)#\\|\\*\\+\\!\\?#$%&/\\]\\[\\{\\}]', '', text)\n",
    "    text = re.sub(r'\\s-\\s', ' ', text)\n",
    "    text = re.sub(r'\\t', '', text)\n",
    "    return text\n",
    "            \n",
    "            \n",
    "#  文字列内の各単語ベクトルを求めその平均を出力する関数\n",
    "#  該当するベクトルがなかったら諦める（0を返す）\n",
    "num_features = 300\n",
    "\n",
    "def avg_feature_vector(title_text,num_features):\n",
    "    words = title_text.replace(':','').replace(';','').replace(\"'\",\"\").replace('\"','').split()\n",
    "    feature_vec = np.zeros((num_features,), dtype=\"float32\") # 特徴ベクトルの入れ物を初期化\n",
    "    for word in words:\n",
    "        try:\n",
    "            feature_vec = np.add(feature_vec, word2vec_model[word])\n",
    "        except:\n",
    "            feature_vec = np.add(feature_vec, np.zeros(num_features))\n",
    "    if len(words) > 0:\n",
    "        feature_vec = np.divide(feature_vec, len(words))# 平均を求める処理 \n",
    "    return feature_vec\n",
    "\n",
    "\n",
    "#  タイトルテキストを一つずつ入力し全事例分の行列を作成する\n",
    "#  numpy array にしたのち　pytorch　用の　tensor　にする\n",
    "def title2vec(title_text):\n",
    "    vec_np_array = np.array([avg_feature_vector(title_word,num_features) for title_word in clean_text(title).split()])\n",
    "    vec_np_array = vec_np_array.astype(np.float32)\n",
    "    return torch.from_numpy(vec_np_array).clone()\n",
    "    \n",
    "    \n",
    "# カテゴリを数値に変換\n",
    "def category2label(category):\n",
    "    labels = {'b': 0, 't': 1, 'e': 2, 'm': 3}\n",
    "    return labels[category]\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    args = parse_args()\n",
    "    data_path = args. data_path\n",
    "    for title, category in make_title_and_category(data_path):\n",
    "        title_tensor = title2vec(title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c974612-306a-4375-b1dd-d02b6bb22b34",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5c9e31d-2e4a-471c-91a1-563a2be688cb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
